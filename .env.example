# Ollama Configuration (using local Mistral model)
OLLAMA_BASE_URL=http://localhost:11434

# Hugging Face Token (optional, for some models)
HUGGINGFACE_TOKEN=your_huggingface_token_here

# Application settings
ENVIRONMENT=development
DEBUG=true
